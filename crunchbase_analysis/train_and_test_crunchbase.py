## This file trains and tests the RNN in inference.py with data sets generated by models.py

# If you use conda please install pytorch using "conda install -c anaconda pytorch" this installs torch v0.3.0
# as of 2/13/2018. If you use "conda install pytorch-cpu torchvision -c pytorch" a different torch version (0.3.1)
# is installed and there would be some error.

from inference import *
from models import *

RD.seed()


def process_cruchbase_timeseries(network_timeseries, input_type):
    if input_type == 'clustering':
        all_nodes_clustering = list(
            map(lambda node_pointer: list(map(lambda network: 1.0 * (NX.clustering(network, node_pointer)),
                                              network_timeseries)), network_timeseries[0].nodes()))
        df = pd.DataFrame(np.transpose(all_nodes_clustering))
    elif input_type  == 'transitivity':  # also called global clustering coefficient
        transitivity_timeseies = list(map(lambda network: 1.0 * (NX.transitivity(network)), network_timeseries))
        df = pd.DataFrame(transitivity_timeseies)
    elif input_type == 'avg_clustering':
        all_nodes_clustering = list(
            map(lambda node_pointer: list(map(lambda network: 1.0 * (NX.clustering(network, node_pointer)),
                                              network_timeseries)), network_timeseries[0].nodes()))
        avg_clustering_timeseries = np.sum(all_nodes_clustering, 0) / NX.number_of_nodes(network_timeseries[0])
        df = pd.DataFrame(avg_clustering_timeseries)

    crunchbase_test_data = torch.FloatTensor(df.values[:, 0:settings.params['feature_length']])
    print(crunchbase_test_data)
    return crunchbase_test_data


if __name__ == '__main__':

    dynamics = UtilityModel(settings.params)


    model = RNN()

    model.empty_losses()

    print('pretraining performance on the traning set')

    training_sample0 = dynamics.gen_torch_data_set(LOAD=True, filename='crunchbase_simulated_dataset1_500.pkl')
    training_sample1 = dynamics.gen_torch_data_set(LOAD=True, filename='crunchbase_simulated_dataset3_500.pkl')
    training_sample2 = dynamics.gen_torch_data_set(LOAD=True, filename='crunchbase_simulated_dataset4_500.pkl')
    training_sample3 = dynamics.gen_torch_data_set(LOAD=True, filename='crunchbase_simulated_dataset5_500.pkl')
    training_sample = training_sample0 + training_sample1 + training_sample2 + training_sample3
    # print(100 * model.evaluateAveragePerformance(training_sample))
    # print(training_sample)
    
    # print(dynamics.params)


    print('size', dynamics.params['size'])

    print('doTraining on the traning set')

    # model.doTraining(training_sample, batch_size = settings.BATCH_SIZE, window_length_loss=settings.WINDOW_LENGTH, verbose = True,
    #                  save = True, file_name = 'model_tuned.pkl')

    model = model.load_from_file('model_tuned_crunchbase_simulated_database.pkl')

    print('perforamce on Trainging set AFTER')
    # print(100 * model.evaluateAveragePerformance(training_sample))
    model.plot_losses()
    model.save_losses()
    # print(model.training_losses)



    print('Test performance on the test set')
    test_sample = dynamics.gen_torch_data_set(LOAD=True, filename='crunchbase_simulated_dataset2_500.pkl')
    print(100 * model.evaluateAveragePerformance(test_sample))
    #
    print('Test performance on the crunchbase data')
    network_timeseries = model.load_from_file('observed_time_series.pkl')
    test_crucnbase = process_cruchbase_timeseries(network_timeseries, settings.params['input_type'])
    print('The model output on the Crunchbase data is:')
    print(model.getSamplePrediction(test_crucnbase))